{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-training\n",
    "\n",
    "The execution of this notebook denotes one iteration in the self-training process.\n",
    "\n",
    "The oracle is assumed to be already trained an stored in `models/oracle`.\n",
    "\n",
    "Firstly a u-net is trained using the supervised data in the first iteration.\n",
    "\n",
    "The trained segmenter computes segmentation for unsupervised data. \n",
    "\n",
    "The oracle determines the highly confident predictions (either in class 5 or 0 in the `buckets_classification` modality).\n",
    "\n",
    "A sampling using the size of the computed liver is performed. All selected samples are inserted into the training data (see last line).\n",
    "\n",
    "Re-execute the notebook to carry out a new iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, random, json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from libs.generators.utils import get_case_length, get_x_slice, get_y_slice\n",
    "from libs.models.u_net import get_model_unet\n",
    "from libs.postprocessing import self_ensembling\n",
    "from libs.generators.utils import get_x_case, get_y_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model and batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_unet(input_size = (416, 416, 1), feature_maps = 16, output_layers=1, output_type='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.generators.ssl_batch_generator import SemiSupervisedBatchGenerator\n",
    "\n",
    "gen = SemiSupervisedBatchGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from libs.metrics import dice_coef_sig\n",
    "\n",
    "model.compile(optimizer= Adam(lr=1e-4, clipnorm=1., clipvalue=0.5), loss='binary_crossentropy', metrics=[ dice_coef_sig, 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(gen, epochs = 120, verbose= 1, workers = 32, max_queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= Adam(lr=1e-5, clipnorm=1., clipvalue=0.5), loss='binary_crossentropy', metrics=[dice_coef_sig, 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, epochs = 30, verbose= 1, workers = 32, max_queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.keras_checkpoints import load_model, save_model\n",
    "\n",
    "oracle = load_model('models/oracle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and collection of highly confident data by the oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unsupervised_samples(supervised= 0):\n",
    "    '''Getter of unsupervised data indices.\n",
    "    @param supervised The id of the supervised volume\n",
    "    @return indices of unsupervised data\n",
    "    '''\n",
    "    indices = []\n",
    "    with h5py.File('data/training_data.h5', 'r') as hdf:\n",
    "        for i in range(0, 20):\n",
    "            if i == supervised:\n",
    "                continue\n",
    "            l = get_case_length(hdf, i)\n",
    "            for j in range(l):\n",
    "                indices.append((i, j))\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = get_unsupervised_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "def stack_segmentation_rgb(x, y):\n",
    "    b = np.full(x.shape, x.mean(), 'float32')\n",
    "    g = x + y.reshape(416, 416, 1)\n",
    "    return batch_normalization(np.concatenate((x, g, b), axis= -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_high_iou = []\n",
    "collected_undefined_iou = []\n",
    "\n",
    "with h5py.File('data/training_data.h5', 'r') as hdf:\n",
    "    print('Start evaluating unlabeled data')\n",
    "    for index in indices:\n",
    "        x = get_x_slice(hdf, index[0], index[1])\n",
    "        P = self_ensembling(x, model)\n",
    "        rgb = stack_segmentation_rgb(x, P)\n",
    "        oracle_verdict = np.argmax(oracle.predict(rgb.reshape(1, 416, 416, 3))[0])\n",
    "        if oracle_verdict == 5: # in P_{high}\n",
    "            # print('Axial slice %i of patient %i is classified as confident prediction.'%(index[0], index[1]))\n",
    "            collected_high_iou.append((index[0], index[1], P, int(P.sum())))\n",
    "        if oracle_verdict == 0 and P.sum() == 0: # in P_{nan}\n",
    "            # print('Axial slice %i of patient %i is classified in the NaN class.'%(index[0], index[1]))\n",
    "            collected_undefined_iou.append((index[0], index[1], P, int(P.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling using the size of the predicted livers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(collected_data, generator, liver_area = 35000):\n",
    "    tau = 5 # min data to add at each iteration\n",
    "    \n",
    "    Pn = 0\n",
    "    while Pn < tau and 0 < liver_area :\n",
    "        liver_area = liver_area - 1000\n",
    "        sampled = filter(lambda x: x[3] > tau, collected_data)\n",
    "        Pn = generator.count_new_samples(sampled)\n",
    "    return sampled;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confident_data = sampling(collected_high_iou, gen)\n",
    "random.shuffle(collected_undefined_iou)\n",
    "sampled_nan = collected_undefined_iou[:len(high_confident_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the semi-supervised dataset and add new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.init_ssl_database import init_ssl_database\n",
    "\n",
    "gen.close_files()\n",
    "init_ssl_database()\n",
    "gen = SemiSupervisedBatchGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.add_separate_samples(high_confident_data, sampled_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
